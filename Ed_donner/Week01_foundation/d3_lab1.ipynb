{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efd372d",
   "metadata": {},
   "source": [
    "# Orchastrating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e219e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83572fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading api_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eaae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User message\n",
    "content = \"\"\"\n",
    "Please, Come up with a chalenging, naunced question that i can ask a number of LLMs to evaluate their intelligence.\n",
    "answer only with the question, no explanation\n",
    "\"\"\"\n",
    "message = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': content\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating question\n",
    "response = client.chat.completions.create(\n",
    "    model='openai/gpt-oss-20b',\n",
    "    messages=message\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are a policy analyst tasked with creating a national strategy to manage the rapid integration of AI into the workforce. The strategy must address potential displacement of workers, ensure equitable access to reskilling opportunities, protect privacy, and maintain competitive advantage in the global economy. What multiâ€‘layered approach would you recommend, and how would you measure its success over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for comparing models\n",
    "competators = []\n",
    "answers = []\n",
    "message = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': question\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9cfd7",
   "metadata": {},
   "source": [
    "### generating answer with 5 different models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc11b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini-2.0-flash\n",
    "client = OpenAI(\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# generating answer\n",
    "response = client.chat.completions.create(\n",
    "    model='gemini-2.0-flash',\n",
    "    messages=message\n",
    ")\n",
    "ans = response.choices[0].message.content\n",
    "Markdown(print(ans))\n",
    "\n",
    "competators.append('gemini-2.0-flash')\n",
    "answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepseek model\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    "    api_key=os.getenv('SAMBANOVA_API_KEY')\n",
    ")\n",
    "\n",
    "# generating answer\n",
    "response = client.chat.completions.create(\n",
    "    model=\"DeepSeek-V3-0324\",\n",
    "    messages=message\n",
    ")\n",
    "ans = response.choices[0].message.content\n",
    "competators.append(\"DeepSeek-V3-0324\")\n",
    "answers.append(ans)\n",
    "Markdown(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groq\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")\n",
    "\n",
    "# GENERATING answer\n",
    "response = client.chat.completions.create(\n",
    "    model=\"groq/compound\",\n",
    "    messages=message\n",
    ")\n",
    "ans = response.choices[0].message.content\n",
    "competators.append(\"groq/compound\")\n",
    "answers.append(ans)\n",
    "Markdown(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d12dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openrouter\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv('OPENROUTER_API_KEY')\n",
    ")\n",
    "\n",
    "# genrating ans\n",
    "response = client.chat.completions.create(\n",
    "    model=\"minimax/minimax-m2\",\n",
    "    messages=message\n",
    ")\n",
    "ans=response.choices[0].message.content\n",
    "competators.append('minimax/minimax-m2')\n",
    "answers.append(ans)\n",
    "Markdown(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a383d1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To develop a comprehensive national strategy for managing the integration of AI into the workforce, I recommend a multi-layered approach consisting of four pillars: Reskilling and Upskilling, Job Creation and Retraining, Data Governance and Protection, and Inclusive Economic Growth. Here's a detailed outline of each pillar and potential metrics for measuring success:\n",
       "\n",
       "**Pillar 1: Reskilling and Upskilling**\n",
       "\n",
       "* Develop a national framework for lifelong learning and continuous skill development, focusing on emerging technologies such as AI, data science, and cybersecurity.\n",
       "* Establish partnerships between education institutions, industry, and governments to create programs that provide accessible, affordable, and relevant training.\n",
       "* Implement tax incentives and funding mechanisms for businesses to invest in employee reskilling and upskilling.\n",
       "* Metrics:\n",
       "\n",
       "1. Percentage of workers participating in reskilling programs.\n",
       "2. Average increase in skills and knowledge among workers.\n",
       "3. Reduction in unemployment rates among workers displaced by AI.\n",
       "\n",
       "**Pillar 2: Job Creation and Retraining**\n",
       "\n",
       "* Identify and support the development of new industries and job roles created by AI, such as AI development, deployment, and maintenance.\n",
       "* Foster entrepreneurship and innovation by providing funding, mentorship, and resources for start-ups and small businesses.\n",
       "* Implement flexible work arrangements and job sharing to accommodate workers transitioning between jobs.\n",
       "* Metrics:\n",
       "\n",
       "1. Number of new jobs created in AI-driven industries.\n",
       "2. Increase in entrepreneurship and start-up businesses.\n",
       "3. Reduction in job displacement rates.\n",
       "\n",
       "**Pillar 3: Data Governance and Protection**\n",
       "\n",
       "* Develop and enforce strict data protection regulations to safeguard workers' personal data and prevent bias in AI decision-making.\n",
       "* Establish a data sharing framework for the development of AI, allowing for transparent and secure data exchange between organizations.\n",
       "* Implement guidelines for responsible AI development and deployment, including transparency, accountability, and explainability.\n",
       "* Metrics:\n",
       "\n",
       "1. Reduction in data breaches and cyber attacks.\n",
       "2. Increase in data sharing and collaboration between organizations.\n",
       "3. Public trust and confidence in AI decision-making.\n",
       "\n",
       "**Pillar 4: Inclusive Economic Growth**\n",
       "\n",
       "* Implement policies to address the impact of AI on low-skilled and vulnerable populations, including education, training, and support services.\n",
       "* Foster inclusive economic growth by promoting entrepreneurship, innovation, and job creation in underserved communities.\n",
       "* Develop a national AI ethics framework that prioritizes human well-being, safety, and dignity.\n",
       "* Metrics:\n",
       "\n",
       "1. Increase in economic activity and job creation in underserved communities.\n",
       "2. Reduction in poverty and income inequality.\n",
       "3. Increase in public trust and confidence in AI decision-making.\n",
       "\n",
       "**Implementation and Monitoring**\n",
       "\n",
       "* Establish a national AI workforce development board to oversee the implementation of this strategy and provide guidance on best practices.\n",
       "* Conduct regular assessments and evaluations to track progress, identify areas for improvement, and adjust the strategy as needed.\n",
       "* Develop a national AI workforce development database to collect and analyze data on workforce development, AI job creation, and economic growth.\n",
       "\n",
       "**Timeline**\n",
       "\n",
       "* Short-term (0-2 years): Establish partnerships, develop training programs, and implement data protection regulations.\n",
       "* Mid-term (2-5 years): Scale up reskilling programs, foster entrepreneurship and innovation, and develop AI ethics guidelines.\n",
       "* Long-term (5-10 years): Achieve widespread adoption of AI-driven industries, significant job creation in underserved communities, and substantial reduction in unemployment rates.\n",
       "\n",
       "**Budget Allocation**\n",
       "\n",
       "* Pillar 1: 30% - Education and Training (upskilling and reskilling programs)\n",
       "* Pillar 2: 25% - Job Creation and Retraining (support for entrepreneurship and innovation)\n",
       "* Pillar 3: 20% - Data Governance and Protection (data sharing framework, AI ethics framework)\n",
       "* Pillar 4: 25% - Inclusive Economic Growth (policy and program development for underserved communities)\n",
       "\n",
       "By adopting this multi-layered approach and measuring success over time, we can ensure a smooth transition to an AI-driven workforce, address potential displacement of workers, and maintain competitive advantage in the global economy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llama-3.1-8b-instant\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv('GROQ_API_KEY')\n",
    ")\n",
    "\n",
    "# GENERATING answer\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=message\n",
    ")\n",
    "ans = response.choices[0].message.content\n",
    "competators.append(\"llama-3.1-8b-instant\")\n",
    "answers.append(ans)\n",
    "Markdown(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a88e4cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gemini-2.0-flash',\n",
       " 'DeepSeek-V3-0324',\n",
       " 'groq/compound',\n",
       " 'minimax/minimax-m2',\n",
       " 'llama-3.1-8b-instant']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bdf2a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787343a",
   "metadata": {},
   "source": [
    "## Ranking our models based on the answers using LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e88ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "together=\"\"\n",
    "for index, ans in enumerate(answers):\n",
    "    together += f\"# Response from competator {index+1}\\n\\n\"\n",
    "    together += ans + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69db9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competators)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6c22379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "class OutputFormat(BaseModel):\n",
    "    model_index: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c0b9d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"results\": [\n",
      "    \"3\",\n",
      "    \"4\",\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"5\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# gemini-2.0-flash\n",
    "client = OpenAI(\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# generating answer\n",
    "response = client.chat.completions.create(\n",
    "    model='gemini-2.5-pro',\n",
    "    messages=[{\n",
    "        'role':'user',\n",
    "        'content': judge\n",
    "    }]\n",
    ")\n",
    "ans = response.choices[0].message.content\n",
    "Markdown(print(ans))\n",
    "\n",
    "competators.append('gemini-2.0-flash')\n",
    "answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73eb39f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"results\": [\\n    \"3\",\\n    \"4\",\\n    \"1\",\\n    \"2\",\\n    \"5\"\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da75659",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Markdown expects text, not <IPython.core.display.Markdown object>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ans = \u001b[43mMarkdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mstr\u001b[39m(ans)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/study/CompleteAgenticAI/.venv/lib/python3.12/site-packages/IPython/core/display.py:344\u001b[39m, in \u001b[36mDisplayObject.__init__\u001b[39m\u001b[34m(self, data, url, filename, metadata)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.metadata = {}\n\u001b[32m    343\u001b[39m \u001b[38;5;28mself\u001b[39m.reload()\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/study/CompleteAgenticAI/.venv/lib/python3.12/site-packages/IPython/core/display.py:423\u001b[39m, in \u001b[36mTextDisplayObject._check_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expects text, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m.data))\n",
      "\u001b[31mTypeError\u001b[39m: Markdown expects text, not <IPython.core.display.Markdown object>"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7a89e98",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# OK let's turn this into results!\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results_dict = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m ranks = results_dict[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranks):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "import json\n",
    "results_dict = json.loads(ans)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competators[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4b0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
